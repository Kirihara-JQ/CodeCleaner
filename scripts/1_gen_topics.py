# æ–‡ä»¶è·¯å¾„: scripts/1_gen_topics.py
import json
import sys
import os

# æŠŠå½“å‰ç›®å½•åŠ å…¥è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ° llm_utils
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from llm_utils import get_completion


def generate_topics():
    print("â³ æ­£åœ¨è¯·æ±‚ AI ç”Ÿæˆé¢˜ç›®...")
    prompt = """
    è¯·ç”Ÿæˆ 50 ä¸ª Python ç¼–ç¨‹ç»ƒä¹ é¢˜ç›®ã€‚

    è¦æ±‚ï¼š
    1. é¢˜ç›®è¦å…·ä½“ï¼Œæ¶µç›–åŸºç¡€é€»è¾‘ã€å­—ç¬¦ä¸²å¤„ç†ã€åˆ—è¡¨/å­—å…¸æ“ä½œã€‚
    2. ä¸è¦å¤ªéš¾ï¼ˆé¿å…å¤æ‚çš„åŠ¨æ€è§„åˆ’ï¼‰ï¼Œé€‚åˆåˆå­¦è€…ç»ƒä¹ ã€‚
    3. æ ¼å¼ä¸¥æ ¼è¦æ±‚ï¼šåªè¾“å‡ºä¸€ä¸ª JSON åˆ—è¡¨ï¼Œä¸è¦ Markdown æ ‡è®°ï¼Œä¸è¦å¤šä½™åºŸè¯ã€‚

    ç¤ºä¾‹ï¼š
    ["ç¼–å†™å‡½æ•°è®¡ç®—åˆ—è¡¨å¹³å‡å€¼", "åè½¬å­—ç¬¦ä¸²å¹¶å¤§å°å†™äº’æ¢", "ç»Ÿè®¡å­—å…¸ä¸­å€¼å¤§äº10çš„é”®"]
    """

    response = get_completion(prompt)

    if response:
        clean_text = response.replace("```json", "").replace("```", "").strip()
        try:
            topics = json.loads(clean_text)
            return topics
        except json.JSONDecodeError:
            print("âš ï¸ è§£æ JSON å¤±è´¥ï¼ŒAI è¿”å›æ ¼å¼ä¸å¯¹ã€‚")
    return []


if __name__ == "__main__":
    # å®šä¹‰æ–‡ä»¶è·¯å¾„
    base_dir = os.path.dirname(os.path.dirname(__file__))
    dataset_dir = os.path.join(base_dir, "dataset")
    save_path = os.path.join(dataset_dir, "topics.json")

    os.makedirs(dataset_dir, exist_ok=True)

    # --- å…ˆè¯»å–æ—§æ•°æ® ---
    all_topics = []
    if os.path.exists(save_path):
        print(f"ğŸ“‚ å‘ç°å·²æœ‰é¢˜ç›®æ–‡ä»¶ï¼Œæ­£åœ¨è¯»å–...")
        try:
            with open(save_path, "r", encoding="utf-8") as f:
                all_topics = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½å·²æœ‰é¢˜ç›®ï¼š{len(all_topics)} ä¸ª")
        except Exception as e:
            print(f"âš ï¸ è¯»å–æ—§æ–‡ä»¶å¤±è´¥ï¼Œå°†é‡æ–°å¼€å§‹: {e}")
            all_topics = []
    else:
        print("ğŸ“‚ æœªå‘ç°æ—§æ–‡ä»¶ï¼Œå¼€å§‹æ–°åˆ›å»º...")

    initial_count = len(all_topics)

    # --- ç»§ç»­ç”Ÿæˆ ---
    for i in range(100):
        print(f"--- ç¬¬ {i + 1} è½®è¿½åŠ ç”Ÿæˆ ---")
        new_topics = generate_topics()
        if new_topics:
            print(f"ğŸŒŸ æœ¬è½®ç”Ÿæˆäº† {len(new_topics)} ä¸ªé¢˜ç›®")
            all_topics.extend(new_topics)
        else:
            print("âš ï¸ æœ¬è½®ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡")

    # --- å…³é”®æ­¥éª¤ï¼šå»é‡ ---
    unique_topics = list(set(all_topics))
    print(f"ğŸ§¹ å»é‡å‰: {len(all_topics)} -> å»é‡å: {len(unique_topics)}")

    # --- ä¿å­˜å›æ–‡ä»¶ ---
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(unique_topics, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ‰ æ›´æ–°å®Œæˆï¼æ€»è®¡ä¿å­˜ {len(unique_topics)} ä¸ªé¢˜ç›®ã€‚")
    print(f"ğŸ“ˆ æœ¬æ¬¡æ–°å¢: {len(unique_topics) - initial_count} ä¸ª")