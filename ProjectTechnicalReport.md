# Code Cleaner 项目技术报告

**项目名称**：Code Cleaner - 基于 Agent 闭环数据合成的代码重构专家

###### Generated by Jiaqi Shi

---

## 1. 项目摘要与背景 (Abstract)

### 1.1 问题陈述
在软件工程领域，遗留代码（Legacy Code）的维护是巨大的痛点。这些代码通常缺乏文档、变量命名混乱、且不符合现代编程规范（如 Google Python Style Guide）。通用大语言模型（如 GPT-4）虽然具备重构能力，但在私有化部署、推理成本和数据隐私方面存在局限。

### 1.2 解决方案
本项目提出了一种“**数据为中心**（Data-Centric）”的解决方案。我们不依赖开源数据集，而是设计了一个包含 **Generator（生成者）、Teacher（教师）、Verifier（验证者）** 的多智能体闭环系统，自主合成了高质量的代码重构数据集（Code Refactoring Dataset）。基于此数据，我们利用 **LoRA** 技术微调了 **Qwen2.5-Coder-1.5B** 模型，使其在极低的参数量下实现了专家级的代码重构能力。

---

## 2. 系统架构与算法设计 (System Architecture)

本系统的核心创新在于“**逆向数据合成**”与“**沙箱验证闭环**”。
![](https://directionaivideo.oss-cn-beijing.aliyuncs.com/assignment/784782335076745216.png)
###### （Figure 1: High-Level System Architecture and Inference Flow）

### 2.1 逆向数据合成流水线 (Reverse Synthesis Pipeline)
为了构建 `(Dirty Code, Clean Code)` 的配对数据，我们设计了如下算法流程：

1.  **Topic Generation (题目生成)**：
    *   调用 DeepSeek/GPT API 生成涵盖字符串处理、列表操作、数学逻辑等 900+ 个 Python 编程题目。
2.  **Dirty Code Synthesis (脏代码合成)**：
    *   **Prompt 设计**：要求 Agent 扮演“新手程序员”，故意生成变量名无意义（`a`, `b`, `x`）、缺乏注释、逻辑冗余的代码。
3.  **Refactoring (专家重构)**：
    *   **Prompt 设计**：要求 Agent 扮演“Google 高级工程师”，对脏代码进行重构。强制要求：添加 Type Hints（类型提示）、Docstrings（文档字符串）、并优化变量命名。

### 2.2 核心算法：沙箱验证闭环 (The Verifier)
这是本项目区别于普通微调的关键技术。为了防止 LLM 产生“幻觉”（即重构后的代码逻辑被改变），我们引入了代码执行沙箱。

*   **对应模块**：`verify_code_pair` 函数 (位于 `scripts/2_data_pipeline.py`)
*   **算法逻辑**：
    1.  **动态测试用例生成**：Agent 针对当前题目自动生成 3 组边界测试输入（如空列表、负数等）。
    2.  **双盲执行**：使用 Python 的 `exec()` 函数，在独立的命名空间（Namespace）中分别运行“脏代码”和“重构代码”。
    3.  **输出比对**：
        $$ Output_{bad} == Output_{good} $$
    4.  **决策机制**：只有当两者在所有测试用例下的运行结果**严格一致**时，该数据样本才会被标记为“有效”并存入数据集。

![](https://directionaivideo.oss-cn-beijing.aliyuncs.com/assignment/784780507664629760.png)
###### （Figure 2: The "Generator-Verifier" Closed-Loop Data Synthesis Pipeline.）
---

## 3. 关键功能模块说明 (Implementation Details)

### 3.1 数据流水线
*   **原子化处理**：`process_single_topic` 函数串联了生成、重构、测试用例生成和验证四个步骤。任一步骤失败（如代码解析错误、验证不通过）即丢弃该样本，保证数据纯度。
*   **鲁棒提取**：实现了基于正则表达式的代码提取逻辑，能够从 LLM 冗长的 Markdown 回复中精准提取 Python 代码块。

### 3.2 模型推理与交互 (`app.py`)
*   **LoRA 适配器加载**：
    *   使用 `PeftModel` 将微调后的低秩矩阵（Rank=8/16）挂载到 Qwen2.5-1.5B 基座上。这种方法仅需加载约 20MB 的额外权重，极大地节省了显存。
*   **System Prompt 工程**：
    *   在推理阶段，注入 System Prompt：`"你是一个资深的 Python 代码重构专家..."`，激活模型的特定潜能，确保输出风格与训练数据一致。
*   **UI 设计**：
    *   使用 Gradio 构建了赛博朋克风格（Cyberpunk Style）的前端，通过 CSS 注入实现了用户输入（蓝色）与 Agent 输出（绿色）的视觉分离，提升了用户体验。

---

## 4. 实验结果与分析 (Experimental Results)

### 4.1 数据集合成质量
*   **原始题目数**：1700+
*   **沙箱通过率**：约 **25%**。这意味着有 75% 的生成数据因逻辑错误或运行报错被自动过滤。这一严苛的过滤机制是模型可靠性的保证。
*   **最终数据集**：约 400 条高质量指令微调数据（SFT Data）。

### 4.2 训练过程分析 (Training Analysis)
受本地GPU性能限制，因此我们使用 Google Colab (Tesla T4) 进行了为期 5 个 Epoch 的微调。

**Loss 下降趋势：**
如下图所示，训练 Loss 呈现清晰的下降趋势：
*   **初始阶段 (Epoch 0-1)**：Loss 从 **0.61** 迅速下降至 **0.41**，模型快速适应了指令格式。
*   **收敛阶段 (Epoch 3-5)**：Loss 稳定在 **0.23 - 0.25** 之间，未出现明显的过拟合（Overfitting）。

![](https://directionaivideo.oss-cn-beijing.aliyuncs.com/assignment/784772248903892992.png)
###### （Figure 3: Train Loss Curve:Code Cleaner）

### 4.3 性能定性评估 (Case Study)
在对比测试中，微调后的模型展现了显著的风格迁移能力：

| 特性 | Base Model (Qwen-1.5B) | **Code Cleaner (Ours)** |
| :--- | :--- | :--- |
| **变量命名** | 保留原样或简单修改 | **语义化命名** (e.g., `x` -> `user_input`) |
| **类型提示** | 偶尔添加 | **强制添加** (e.g., `-> float`) |
| **文档注释** | 简略 | **Google Style Docstring** (Args, Returns) |

![](https://directionaivideo.oss-cn-beijing.aliyuncs.com/assignment/784782570662412288.png)
###### （Figure 3: Qualitative Comparison of Input (Legacy Code) vs. Model Output.）
---

## 5. 总结与展望 (Conclusion)

本项目成功验证了 **“小模型 + 高质量合成数据 > 通用大模型 + 零样本推理”** 的假设。通过构建自动化的 Agent 数据生产线，我们以极低的成本获得了具有高度专业性的代码重构模型。该系统具备完整的闭环验证机制，解决了 LLM 在代码生成任务中常见的可靠性问题，具有较高的工程实用价值。

