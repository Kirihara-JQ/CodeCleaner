# Code Cleaner: 基于 Agent 闭环数据合成的代码重构专家


 **项目名称**：Code Cleaner (遗留代码自动重构系统)

###### Generated by Jiaqi Shi

## 📖 项目简介 (Project Overview)

针对软件工程中普遍存在的“遗留代码（Legacy Code）维护难”问题，本项目构建了一个**基于 LLM Agent 的自动化数据合成流水线**。

我们摒弃了传统的开源数据集微调范式，创新性地设计了 **"Generator - Teacher - Verifier"** 的多智能体协作架构，自主生产了高质量的代码重构数据集。最终，我们基于 **Qwen2.5-Coder-1.5B** 基座模型，使用 LoRA 技术蒸馏出了一个轻量级、可私有化部署的代码重构专用模型。该模型不仅能优化代码逻辑，还能自动补充符合 Google Style 的文档和类型提示。

## ✨ 核心创新点 (Key Highlights)

本项目在技术实现上不仅限于 API 调用，而是深入到了**数据为中心 (Data-Centric AI)** 的核心：

1.  **闭环验证机制 (Closed-Loop Verification)**：
    *   **痛点解决**：解决了大模型生成代码容易出现逻辑错误（幻觉）的问题。
    *   **实现方式**：引入 Python 代码沙箱作为“裁判”。Agent 自动生成测试用例，分别运行“烂代码”和“重构后代码”。**只有当两者运行结果严格一致时，数据才会被收录**。
    *   **成果**：从 1000+ 个原始题目中，清洗出 ~400 条高纯度黄金数据。

2.  **逆向数据合成 (Reverse Synthesis)**：
    *   采用“先生成低质代码 -> 再由专家重构”的逆向策略，模拟了真实开发场景中的重构过程，极大降低了数据获取成本。

3.  **高效知识蒸馏**：
    *   验证了 1.5B 参数量的小模型，在高质量特定领域数据（SFT）的加持下，可以习得 GPT-4 级别的代码规范风格。

## 📂 项目文件结构

```text
CodeCleaner_Submission/
│
├── dataset/                 # [核心资产] 自主合成的数据集
│   ├── topics.json          # 自动生成的 1000+ 编程题目库
│   └── code_refactor.jsonl  # 经过沙箱验证的 ~400 条高质量指令微调数据
│
├── model/                   # [模型权重] 训练成果
│   ├── adapter_model.safetensors  # LoRA 权重本体
│   ├── adapter_config.json        # LoRA 配置文件
│   └── ...                        # Tokenizer 相关配置文件
│
├── scripts/                 # [工程代码]
│   ├── 1_gen_topics.py      # 题目生成器 (Step 1)
│   ├── 2_data_pipeline.py   # 核心流水线 (Step 2: 生成-重构-验证)
│   ├── demo.py              # 模型推理演示脚本 (用于验收)
│   └── llm_utils.py         # LLM API 接口封装
│
├── training_log/            # [实验记录]
│   └── CodeCleanerTrain.ipynb  # Google Colab上的完整训练日志与Loss曲线
│
├── requirements.txt         # 项目依赖库
└── README.md                # 本文档
```

## 💻 环境配置与运行指南 (Prerequisites)

本项目依赖 Python 3.10+ 环境。为了获得最佳推理体验，建议使用配备 NVIDIA 显卡的环境（显存 > 4GB）。

1.  **创建虚拟环境 (推荐)**
```bash
# 创建环境
python -m venv venv

# 激活环境 (Windows)
.\venv\Scripts\activate

# 激活环境 (Mac/Linux)
source venv/bin/activate
```

2.  **安装依赖库**
```bash
pip install -r requirements.txt
```
注：本项目依赖 torch, transformers, peft 等深度学习库。如果下载速度慢，请使用清华源或阿里源。

## 🚀 演示运行 (Run Demo)

我们提供了一个一键运行的演示脚本，它会自动加载我们训练好的 LoRA 权重，演示模型如何“化腐朽为神奇”。

**注意：运行此演示脚本不需要 API Key。**

```bash
python app.py
```

**预期输出：**
脚本会自动下载基座模型 **Qwen/Qwen2.5-Coder-1.5B-Instruct**(首次运行约需下载 3GB)。 加载本地 model/ 目录下的微调权重。
控制台将打印一段混乱的输入代码，以及模型输出的完美重构代码（包含规范的变量名、Type Hints 和文档注释）。

## 🛠️ 复现数据生成 (可选)

如果您希望检查我们的数据生成过程（Agent 交互逻辑），请按照以下步骤操作。

**注意：此步骤需要 DeepSeek 或 OpenAI 的 API Key。**

1. **配置 API Key**

   在项目根目录下创建一个 `.env` 文件，填入您的 Key：

   ```env
   LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
   LLM_BASE_URL=https://api.deepseek.com
   ```
   
2. **运行流水线**
    ```bash
    # 第一步：生成算法题目 (原料)
    python scripts/1_gen_topics.py

    # 第二步：启动工厂流水线 (生成 -> 重构 -> 沙箱验证 -> 保存)
    # 这一步会调用 Python 解释器执行代码，请确保环境安全
    python scripts/2_data_pipeline.py
   ```
   
## 📊 实验结果分析

**数据产出:**
覆盖了约 900 个 Python 基础编程知识点。
流水线通过率约为 40%，有效过滤了大量逻辑不自洽的低质样本。

**训练表现：**
训练平台：Google Colab (Tesla T4 GPU)。
收敛情况：经过 5 个 Epoch，Training Loss 从 0.61 稳定收敛至 0.31。

**定性分析：**
微调后的模型在代码风格迁移任务上表现优异，能够严格遵循 Google Python Style Guide，这是原始 1.5B 模型不具备的能力。



###### Generated by Jiaqi Shi
